#!/usr/bin/env python

#
#  Version 0.1  
#  no speed buffs, no extra functionality, no optimisation
#  Basic Pipeline
#  for multi core desktops, not clusters

# issues:
# 1) if this script is killed, the rosetta will continue
# 2) Theseus can hang, this is killed after a timeout 
# 3) is clustered by all atom RMSD to make fine clusters (option to cluster by CA only i included)
# 4) ASU content is the number of search models placed by MrBUMP. -- need to set this manually

import os
import sys

# Test for environment variables

if not "CCP4" in sorted(os.environ.keys()):
    raise RuntimeError('CCP4 not found')

# Add the ample python folder to the PYTHONPATH

sys.path.append(os.path.join(os.environ["CCP4"], "share", "ample", "python"))

import re
import glob
import subprocess
import shlex
import string
import time
import operator
import argparse
import random
from multiprocessing import Process, Queue, JoinableQueue, Pool, Value, Array
import pickle
import copy
import clusterize
import shutil

from  subprocess import Popen, PIPE, STDOUT
from add_sidechains_SCWRL import *
import cluster_entropy, truncateedit, truncateedit_MAX
import SCWRL_edit, Final_display_results

import run_mr_bump_shelx_parallel
import fasta_parser
import run_spicker

###############

#get a program test for existsnce
def which(program):
    import os
    def is_exe(fpath):
        return os.path.exists(fpath) and os.access(fpath, os.X_OK)

    fpath, fname = os.path.split(program)
    if fpath:
        if is_exe(program):
            return program
    else:
        for path in os.environ["PATH"].split(os.pathsep):
            exe_file = os.path.join(path, program)
            if is_exe(exe_file):
                return exe_file

    return None
#########
def check_for_exe(exename, varname):
   exepath = ''
   print 'looking for', exename
   if not varname:
     print 'no '+exename+' given on the command line, looking in the PATH'
     print which(exename)
     if not which(exename):
       print 'You need to give the path for '+exename
       sys.exit()
     else: 

      exepath = which(exename)
   
   else:
    exepath = varname
    print 'using here',exepath


    
   
   if not os.path.exists(exepath):
    print 'You need to give the path for '+exename+', executable in the PATH dosnt exist'
    sys.exit()
   else:
     return exepath



#-------------------------------------------
#get command line options
#-------------------------------------------

parser = argparse.ArgumentParser(description='Structure solution by abinitio modeling', prefix_chars="-")

parser.add_argument('-ROSETTA', metavar='ROSETTA_path', type=str, nargs=1,
                   help='path for Rosetta AbinitioRelax')

parser.add_argument('-RDB', metavar='ROSETTA_database', type=str, nargs=1,
                   help='path for Rosetta database')

parser.add_argument('-fragsexe', metavar='path to make_fragments.pl', type=str, nargs=1,
                   help='location of make_fragments.pl')

parser.add_argument('-Rosetta_cluster', metavar='path to Rosettas cluster', type=str, nargs=1,
                   help='location of rosetta cluster')


parser.add_argument('-fasta', metavar='fasta_file', type=str, nargs=1,
                   help='protein fasta file. (required)')

parser.add_argument('-name', metavar='priotein name', type=str, nargs=1,
                   help='name of protien in the format ABCD ')


parser.add_argument('-NProc', metavar='NoProcessors', type=int, nargs=1,
                   help='number of processers (default 1)')


parser.add_argument('-RunDir', metavar='run_directory', type=str, nargs=1,
                   help='directory to put files (default current dir)')



parser.add_argument('-SCWRL', metavar='path to scwrl', type=str, nargs=1,
                   help='pathway to SCWRL exe')



parser.add_argument('-LGA', metavar='path_to_LGA dir', type=str, nargs=1,
                   help='pathway to LGA folder (not the exe) will use the \'lga\' executable')


parser.add_argument('-MAX', metavar='Maxcluster exe', type=str, nargs=1,
                   help='Maxcluster exe')


parser.add_argument('-THESEUS', metavar='Theseus exe (required)', type=str, nargs=1,
                   help='Theseus exe')

parser.add_argument('-PHENIX', metavar='PHENIX.ensembler exe', type=str, nargs=1,
                   help='PHENIX exe')

parser.add_argument('-MTZ', metavar='MTZ in', type=str, nargs=1,
                   help='MTZ in')


parser.add_argument('-MODELS', metavar='folder of decoys', type=str, nargs=1,
                   help='folder of decoys')

parser.add_argument('-MakeModels', metavar='Do the modelling', type=str, nargs=1,
                   help='run rosetta modeling, set to False to import pre-made models (required if making models locally default True)')

parser.add_argument('-ROSETTA_DIR', metavar='Rosetta_dir', type=str, nargs=1,
                   help='the Rosetta install directory')

## fragments

parser.add_argument('-make_frags', metavar='bool to make fragments', type=str, nargs=1,
                   help='Bool, True to make non homologous framents, False to import fragments')

parser.add_argument('-3mers', metavar='3mers', type=str, nargs=1,
                   help='path of imported 3mers')

parser.add_argument('-9mers', metavar='9mers', type=str, nargs=1,
                   help='path of imported 9mers') 

## FLAGS
parser.add_argument('-F', metavar='flag for F', type=str, nargs=1,
                   help='Flag for F')

parser.add_argument('-SIGF', metavar='flag for SIGF', type=str, nargs=1,
                   help='Flag for SIGF')

parser.add_argument('-FREE', metavar='flag for FREE', type=str, nargs=1,
                   help='Flag for FREE')

parser.add_argument('-CLUSTER', metavar='using a cluster', type=str, nargs=1,
                   help='will submit jobs to a cluster')

parser.add_argument('-ALLATOM', metavar='using a cluster', type=str, nargs=1,
                   help='will submit jobs to a cluster')

parser.add_argument('-SPICKER', metavar='boolean', type=str, nargs=1,
                   help='path and will use spicker as alternative')

parser.add_argument('-SPICKERPATH', metavar='spicker exe', type=str, nargs=1,
                   help='path and will use spicker as alternative')


parser.add_argument('-domain_all_chains_pdb', metavar='domain_all_chains_pdb', type=str, nargs=1,
                   help='fixed input to mr bump')

parser.add_argument('-domain_all_chain_fasta', metavar='domain_all_chain_fasta', type=str, nargs=1,
                   help='fasta for all ASU')

parser.add_argument('-domain_termini', metavar='termini', type=str, nargs=1,
                   help='distacne between termini for insert domains')


parser.add_argument('-NMODELS', metavar='no models', type=int, nargs=1,
                   help='number of models to make (1000)')


parser.add_argument('-CC', metavar='rad of gyration', type=str, nargs=1,
                   help='radius of gyration reweight ')

parser.add_argument('-ensembles', metavar='enembles', type=str, nargs=1,
                   help='path to ensembles')

parser.add_argument('-noClusters', metavar='no clus to sample', type=str, nargs=1,
                   help='number of clusters to sample')


parser.add_argument('-percent', metavar='no clus to sample', type=str, nargs=1,
                   help='percent interval for truncation')

parser.add_argument('-ASU', metavar='no in ASU', type=int, nargs=1,
                   help='no in ASU')


parser.add_argument('-FreeLunch', metavar='free lunch', type=int, nargs=1,
                   help='true to use free lunch, false to not use it')

parser.add_argument('-usehoms', metavar='nohoms rosetta flag', type=str, nargs=1,
                   help='True =use nhomologs, False= dont use them ')

parser.add_argument('-ImproveTemplate', metavar='improve template', type=str, nargs=1,
                   help='give a template to imrove - NMR, homolog ')

parser.add_argument('-DEBUG', metavar='debug option', type=str, nargs=1,
                   help='debug option ')

parser.add_argument('-ensembler', metavar='ensembler', type=str, nargs=1,
                   help='ensembling')

parser.add_argument('-TRYALL', metavar='TRYALL', type=str, nargs=1,
                     help='terminate early if a success')

parser.add_argument('-NoShelx', metavar='NoShelx', type=str, nargs=1,
                     help='Always use Shelx, if you cant be bothered to ask for the beta version, use this flag (but dont expect it to work)')


parser.add_argument('-NumShelxCyc', metavar='NoShelxCycles', type=str, nargs=1,
                     help='Always use Shelx, if you cant be bothered to ask for the beta version, use this flag (but dont expect it to work)')


#convert args to dictionary
args = parser.parse_args()
 



var_args = vars(args)


#Required commands:


if  var_args['ROSETTA_DIR'] is None:
     print 'you need to give the Rosetta path'
     sys.exit()

if not var_args['ROSETTA_DIR'] is None:
   if var_args['ROSETTA_DIR'][0] != 'none': 
     ROSETTA_OVER_PATH = var_args['ROSETTA_DIR'][0]
   if var_args['ROSETTA_DIR'][0] == 'none':
     print 'you need to give the Rosetta path'
     sys.exit()


if var_args['ROSETTA'] is None:
   ROSETTA_PATH = 'no_path_given'
if not var_args['ROSETTA'] is None: 
   ROSETTA_PATH = var_args['ROSETTA'][0]

if var_args['RDB'] is None:
   ROSETTA_DB = 'no_path_given'
if not var_args['RDB'] is None: 
   ROSETTA_DB = var_args['RDB'][0]


if var_args['fragsexe'] is None:
  Make_fragents_exe = ' '
if not var_args['fragsexe'] is None:
  Make_fragents_exe = var_args['fragsexe'][0] 

if var_args['Rosetta_cluster'] is None:
   ROSETTA_cluster = 'no_path_given'
if not var_args['Rosetta_cluster'] is None: 
   ROSETTA_cluster = var_args['Rosetta_cluster'][0]


if var_args['fasta'] is None:
    FASTA = 'no_fasta_given'
if not var_args['fasta'] is None:
    FASTA = var_args['fasta'][0] 

if var_args['name'] is None:
   PDB_code = 'ABCD'
if not var_args['name'] is None:
   PDB_code =var_args['name'][0]

if var_args['NProc'] is None:
   NProc = 1
if not var_args['NProc'] is None:
   NProc = var_args['NProc'][0]


if var_args['RunDir'] is None:
   RunDir = os.getcwd()
if not var_args['RunDir'] is None:
   RunDir = var_args['RunDir'][0]



if var_args['SCWRL'] is None:
  SCWRL_path = ''
if not var_args['SCWRL'] is None:
 if var_args['SCWRL'][0] !='none':
  SCWRL_path =var_args['SCWRL'][0] 


 



if var_args['MAX'] is None:
  MAX_path = ''
if not var_args['MAX'] is None:
  if var_args['MAX'][0] != 'none':
    MAX_path =var_args['MAX'][0]



if var_args['THESEUS'] is None:
   THESEUS_path = ''
if not var_args['THESEUS'] is None:
  if var_args['THESEUS'][0] != 'none':
   THESEUS_path = var_args['THESEUS'][0]


if var_args['PHENIX'] is None:
   PHENIX_path = ''
if not var_args['PHENIX'] is None:
  if var_args['PHENIX'][0] != 'none':
   PHENIX_path = var_args['PHENIX'][0]





#print var_args['MTZ']
if var_args['MTZ'] is None:
   MTZ = 'none'
if not var_args['MTZ'] is None:
   MTZ = var_args['MTZ'][0]

IMPORTING_MODELS=False
if var_args['MODELS'] is None:
   MODELS_LOCATION = ''
if not var_args['MODELS'] is None:
   MODELS_LOCATION = var_args['MODELS'][0]
   IMPORTING_MODELS=True

MakeModels = True

if var_args['MakeModels'] is None:
   MakeModels = True
if not var_args['MakeModels'] is None:
   if var_args['MakeModels'][0] == 'False':
     MakeModels = False
     print '\nNOT Making Rosetta Models\n'
   if var_args['MakeModels'][0] == 'True':
     MakeModels = True
     print '\nMaking Rosetta Models\n'


NoShelx = False
if var_args['NoShelx'] is None:
   NoShelx = False
if not var_args['NoShelx'] is None:
   if var_args['NoShelx'][0] == 'False':
     NoShelx = False
     print '\nRebuilding in Shelx\n'
   if var_args['NoShelx'][0] == 'True':
     NoShelx  = True
     print '\nWarning, you are not using Shelx\n'
if NoShelx == False:
  print 'Rebuilding in Shelx'  


NoShelxCycles = 15
if var_args['NumShelxCyc'] is None:
   NoShelxCycles = 15
if not var_args['NumShelxCyc'] is None:
   NoShelxCycles = var_args['NumShelxCyc'][0]



###fragments


if var_args['make_frags'] is None:
   MakeFrags = True
if not var_args['make_frags'] is None:
   if var_args['make_frags'][0] == 'False':
     MakeFrags = False
     print '\nNOT Making Fragments\n'
   if var_args['make_frags'][0] == 'True':   
     MakeFrags = True
     print '\nMaking non homologusFragments\n'


if var_args['3mers'] is None:
   frags_3_mers = ''
if not var_args['3mers'] is None:
   frags_3_mers = var_args['3mers'][0]


if var_args['9mers'] is None:
   frags_9_mers = ''
if not var_args['9mers'] is None:
   frags_9_mers = var_args['9mers'][0]


if var_args['usehoms'] is None:
   nohoms = ' -nohoms '
if not var_args['usehoms'] is None:
  if "TRUE" in var_args['usehoms'][0].upper():
      nohoms = ' '
  elif "FALSE" in var_args['usehoms'][0].upper():
      nohoms = ' -nohoms '

##flags
if var_args['F'] is None:
   notused, flag_SIGF, flag_F , flag_FREE  = run_mr_bump_shelx_parallel.get_flags (MTZ)
if not var_args['F'] is None:
   flag_F = var_args['F'][0]
   

if var_args['SIGF'] is None:
   notused, flag_SIGF, flag_F , flag_FREE  = run_mr_bump_shelx_parallel.get_flags (MTZ)
if not var_args['SIGF'] is None:
   flag_SIGF = var_args['SIGF'][0]

if var_args['FREE'] is None:
   notused, flag_SIGF, flag_F , flag_FREE = run_mr_bump_shelx_parallel.get_flags (MTZ)
if not var_args['FREE'] is None:
   flag_FREE = var_args['FREE'][0]

print flag_F, flag_SIGF, flag_FREE

if var_args['CLUSTER'] is None:
   CLUSTER= False
else:
  if "TRUE" in var_args['CLUSTER'][0].upper():
     CLUSTER = True
  elif "FALSE" in var_args['CLUSTER'][0].upper():
     CLUSTER = False
  else:
     CLUSTER = False


EarlyTerminate = False



if var_args['TRYALL'] is None:
    EarlyTerminate = False
else:
   if "FALSE" in var_args['TRYALL'][0].upper():
      EarlyTerminate = True
      print 'will exit at the first success'
   elif "TRUE" in var_args['TRYALL'][0].upper():
      EarlyTerminate = False
   else:
      EarlyTerminate = False   
         
     

 


if var_args['ALLATOM'] is None:
   ALLATOM= False
else:
  if "TRUE" in var_args['ALLATOM'][0].upper():
     ALLATOM = True
  elif "FALSE" in var_args['ALLATOM'][0].upper():
     ALLATOM = False
  else:
     ALLATOM = False

#----------missing domains

MISSING_DOMAINS = False

if var_args['domain_all_chains_pdb'] is None:
   domain_all_chains_pdb='none'
if not var_args['domain_all_chains_pdb'] is None:
    domain_all_chains_pdb= var_args['domain_all_chains_pdb'][0]
    MISSING_DOMAINS = True


if var_args['domain_all_chain_fasta'] is None:
   domain_all_chain_fasta='none'
if not var_args['domain_all_chain_fasta'] is None:
    domain_all_chain_fasta= var_args['domain_all_chain_fasta'][0]
    MISSING_DOMAINS = True


FIXED_INPUT = True


#-------------\missing domains

if var_args['NMODELS'] is None:
    NMODELS = 1000
if not var_args['NMODELS'] is None:
    NMODELS= var_args['NMODELS'][0]


if var_args['percent'] is None:
    percent = 5
    FIXED_INTERVALS = True
if not var_args['percent'] is None:
    percent= var_args['percent'][0]
    FIXED_INTERVALS = False


INSERT_DOMAIN=False
if var_args['domain_termini'] is None:
   
    domain_termini_distance=0
if not var_args['domain_termini'] is None:
    domain_termini_distance= var_args['domain_termini'][0]
    INSERT_DOMAIN=True


CCline=''
if var_args['CC'] is None:
    CCline = ''
if not var_args['CC'] is None:
  if "none" in var_args[''][0].upper():
    CCline= ''
  else:
    CCline= ' -rg_reweight 0 '


ENSEMBLE_import=False
if var_args['ensembles'] is None:
    ENSEMBLES=''
if not var_args['ensembles'] is None:
    ENSEMBLES= var_args['ensembles'][0]
    ENSEMBLE_import =True


USE_SPICKER=True
if var_args['SPICKER'] is None:
    SPICKER = True
if not var_args['SPICKER'] is None:
    SPICKER= True



if var_args['SPICKERPATH'] is None:
    SPICKEREXE_path = ''
if not var_args['SPICKERPATH'] is None:
    SPICKEREXE_path= var_args['SPICKERPATH'][0]
#print 'SPICKEREXE_path ', SPICKEREXE_path



noClusters=1
if var_args['noClusters'] is None:
    noClusters=1 
if not var_args['noClusters'] is None:
    noClusters= var_args['noClusters'][0]


noASU=''
if var_args['ASU'] is None:
    noASU = ''
if not var_args['ASU'] is None:
    noASU = 'NMASU '+ str(var_args['ASU'][0])


if var_args['ImproveTemplate'] is None:
    template = ''
    ImportTemplate =False
if not var_args['ImproveTemplate'] is None:
    template =  var_args['ImproveTemplate'][0]
    ImportTemplate =True


if var_args['FreeLunch'] is None:
    FreeLunch= True
if not var_args['FreeLunch'] is None:
    FreeLunch = var_args['FreeLunch'][0]

DEBUG= False
if var_args['DEBUG'] is None:
    DEBUG= False
if not var_args['DEBUG'] is None:
    D= var_args['DEBUG'][0]
    if re.search('TRUE', D.upper()):
       DEBUG =True


Ensembler = False   # default theseus

if var_args['ensembler'] is None:
    Ensembler = False
if not var_args['ensembler'] is None:
    D= var_args['ensembler'][0]
    if re.search('FALSE', D.upper()):
       Ensembler = False
    if re.search('TRUE', D.upper()):
       Ensembler = True  

#--------------------------------------------
#give the run file to check
	#---------------------------------------------

Run_params = open(RunDir +'/Params_used', "w")
if DEBUG == True:# if debug is on print stuff out
  print var_args
for print_user in var_args:
 if var_args[print_user] is not None:
  if DEBUG == True:
    print print_user +' : ' + str(var_args[print_user][0])

  Run_params.write(print_user +' : ' + str(var_args[print_user][0]) + '\n')
Run_params.close()

#---------------------------------------
#check for errors
#---------------------------------------
LOG = open(RunDir+'/Ample.log', "a")
LOG.write('The authors of specific programs should be referenced where applicable::\n\n'+
           'AMPLE: To be added\n'+
           'SHELX: is used: "A short history of SHELX". Sheldrick, G.M. (2008). Acta Cryst. A64, 112-122/n/n'+ 
           
           'SCWRL: G. G. Krivov, M. V. Shapovalov, and R. L. Dunbrack, Jr. Improved prediction of protein side-chain conformations with SCWRL4. Proteins (2009).\n\n'+
           

           'Theseus: THESEUS: Maximum likelihood superpositioning and analysis of macromolecular structures.\n'+
           'Theobald, Douglas L. & Wuttke, Deborah S. (2006b) Bioinformatics 22(17):2171-2172 [Open Access]\n'+ 
           'Supplementary Materials for Theobald and Wuttke 2006b.\n'+


           'MrBUMP: R.M.Keegan and M.D.Winn (2007) Acta Cryst. D63, 447-457\n'+
            
             
           'CCP4: Collaborative Computational Project, Number 4. (1994), The CCP4 Suite: Programs\n'+ 
           'for Protein Crystallography. Acta Cryst. D50, 760-763\n\n'+
           
           'MOLREP: A.A.Vagin & A.Teplyakov (1997) J. Appl. Cryst. 30, 1022-1025\n\n'+
           
           'PHASER: McCoy, A.J., Grosse-Kunstleve, R.W., Adams, P.D., Winn, M.D.,\n'+
           'Storoni, L.C. & Read, R.J. (2007)\n'+
           'Phaser crystallographic software J. Appl. Cryst. 40, 658-674\n\n'+
           
           'REFMAC: G.N. Murshudov, A.A.Vagin and E.J.Dodson, (1997) Refinement of Macromolecular\n'+ 
           'Structures by the Maximum-Likelihood Method. Acta Cryst. D53, 240-255\n\n'+

           'SPICKER: Y. Zhang, J. Skolnick, SPICKER: Approach to clustering protein structures for near-native model selection, Journal of Computational Chemistry, 2004 25: 865-871\n'+           
           
           'MaxCluster: http://www.sbg.bio.ic.ac.uk/maxcluster/\n')
LOG.flush()              
 
            


print 'Making a Run Directory  -checking for previous runs'
run_inc = 0
run_making_done = False
while run_making_done  == False:
 if not os.path.exists(RunDir + '/ROSETTA_MR_'+str(run_inc)):
  run_making_done = True
  os.mkdir(RunDir + '/ROSETTA_MR_'+str(run_inc))
 run_inc+=1
RunDir = RunDir + '/ROSETTA_MR_'+str(run_inc -1)



if MakeFrags==False:
 if MakeModels == True:
  if not os.path.exists(frags_3_mers):
    print 'Cant find 3mers'
    sys.exit()
  if not os.path.exists(frags_9_mers):
    print 'Cant find 9mers'
    sys.exit()


#check if got all the programs
if MakeModels == False:
 IMPORTING_MODELS = True

if MakeModels == True:
 if IMPORTING_MODELS == True:
  print MODELS_LOCATION
  print 'you have chosen to both import models and to make them, choose only one\nSet Make Models to \"True\" to make them, \"False\" to import them'
  sys.exit()

if IMPORTING_MODELS == True:
  if not os.path.exists(MODELS_LOCATION):
   print 'you have chosen to import models, but path does not exist, looking for ensembles'
   if not os.path.exists(ENSEMBLES):
    print 'you have chosen to import ensembles, but path does not exist'
    sys.exit()


 
 
if MakeModels == True:  #only need Rosetta if making models 

 if not os.path.exists(ROSETTA_OVER_PATH):
  print 'Give the rosetta path on the commabd line'

 if os.path.exists(ROSETTA_OVER_PATH):
   Version_file               =ROSETTA_OVER_PATH+'/README.version'          
   ROSETTA_PATH               =ROSETTA_OVER_PATH+'/rosetta_source/bin/AbinitioRelax.linuxgccrelease'
   ROSETTA_cluster            =ROSETTA_OVER_PATH+'/rosetta_source/bin/cluster.linuxgccrelease'
   ROSETTA_DB                 =ROSETTA_OVER_PATH+'/rosetta_database'
   Make_fragents_exe          =ROSETTA_OVER_PATH+'/rosetta_fragments/nnmake/make_fragments.pl'

 if not os.path.exists(Version_file):
   print 'version not found'
   sys.exit()

 Rosetta_version = '3.2'
 for line in open(Version_file):
   if re.search('Rosetta', line):
       line=re.sub('Rosetta','',line)
       Rosetta_version =  string.strip(line)
 print  'Your Rosetta version is'+ line
        
 if Rosetta_version == '3.3' :
    Make_fragents_exe          =ROSETTA_OVER_PATH+'/rosetta_fragments/make_fragments.pl'

 if Rosetta_version == '3.4' :
    Make_fragents_exe          =ROSETTA_OVER_PATH+'/rosetta_tools/fragment_tools/make_fragments.pl'


 if not os.path.exists(ROSETTA_PATH)  :
   print ' cant find Rosetta abinitio, check path names'
   print ROSETTA_PATH  
   sys.exit()

 if not os.path.exists(ROSETTA_cluster): 
   print ' cant find Rosetta cluster, check path names'
   sys.exit()
 if not os.path.exists(ROSETTA_DB) :
   print ' cant find Rosetta DB, check path names'
   sys.exit()
 if not os.path.exists(Make_fragents_exe):
   print ' cant find make fragments, check path names'
   sys.exit()


if not os.path.exists(FASTA):
    print 'You need to give the path for the fasta'
    sys.exit()

if not os.path.exists(RunDir):
    print 'You need to give a run directory'
    sys.exit()





#if not os.path.exists(LGA):
#  LGA = os.environ.get("LGA_PATH")
#  if not os.path.exists(LGA):
#    print 'You need to give the path for LGA'
#    sys.exit()



if Ensembler  == False:
   THESEUS = check_for_exe('theseus', THESEUS_path)
  # print 'finally got', THESEUS
if Ensembler  == True:
   print 'You are using Phenix ensmbler- Continue at your own risk !!'
   PHENIX = check_for_exe('phenix', PHENIX_path)

SCWRL = check_for_exe('Scwrl4', SCWRL_path )
#print 'finally got', SCWRL
SPICKEREXE = check_for_exe('spicker',SPICKEREXE_path )

#print 'finally got', SPICKEREXE
MAX = check_for_exe('maxcluster', MAX_path)
#print 'finally got', MAX
if NoShelx == False:
   mtz2hkl = ''
   mtz2hkl = check_for_exe('mtz2hkl', mtz2hkl)
   shelxpro = ''
   shelxpro = check_for_exe('shelxpro', shelxpro)
   shelxl = ''
   shelxl = check_for_exe('shelxl', shelxl)
   shelxe=''
   shelxe = check_for_exe('shelxe', shelxe)


if len(PDB_code)>4 or len(PDB_code)<4:
   print 'name is the wrong length, use 4 chars eg ABCD, changing name'
   PDB_code='ABCD'

     
if len(PDB_code)==4: 
   PDB_code +='_'



if not os.path.exists(MTZ):
    print 'need mtz or no MR will be carried out'
    sys.exit()

if ImportTemplate:
   if not os.path.exists(template):
      print 'cant find template to improve'
      sys.exit()



print '\nAll needed programs are found, continuing Run\n'



#----------------------------
# params used
#---------------------------
#make a copy of params
#

Run_params = open(RunDir +'/Params_used', "w")
Run_params.write('input params\n')
if DEBUG == True:
  print var_args
  for print_user in var_args:
   if var_args[print_user] is not None:
     print print_user +' : ' + str(var_args[print_user][0])

     Run_params.write(print_user +' : ' + str(var_args[print_user][0]) + '\n')

Run_params.write('\nParams Used in this Run\n')
Run_params.write('\n---input---\nFasta '+FASTA+'\nRunDir '+RunDir+'\nMTZ '+MTZ+'\nname '+PDB_code+'\n')
Run_params.write('\n---fragments---\nMakeFrags '+str(MakeFrags)+'\n3mers '+frags_3_mers+'\n9mers '+frags_9_mers+'\n')
Run_params.write('\n---modelling---\nMakeModels '+str(MakeModels)+'\nROSETTA_PATH '+ROSETTA_PATH+'\n')
Run_params.write('ROSETTA_cluster '+ROSETTA_cluster+'\nROSETTA_DB '+ROSETTA_DB+'\nMake_fragents_exe '+Make_fragents_exe+'\n')
Run_params.write('\n---3rd party---\nSCWRL '+SCWRL+'\n')
Run_params.write('\n---Missing Domain---\nall chains fasta '+domain_all_chain_fasta+'\nall chain pdb '+domain_all_chains_pdb+'\nMISSING DOMAINS='+str(MISSING_DOMAINS)+'\n')
Run_params.write('Is an Insert Domain '+str(INSERT_DOMAIN)+ ' termini distance '+ str(domain_termini_distance) +'\n')

Run_params.close()



#-----------------------------------
#Do The Modelling
#-----------------------------------
seedlog = open(RunDir+'/seedlist', "w")
time_start=time.time()
RUNNING=open( RunDir +'/ROSETTA.log', "w")

RUNNING.write('#########################################################################\n'+
           '#########################################################################\n'+
           '#########################################################################\n'+
           '# CCP4: AMPLE -Ab Initio Modelling Molecular Replacement (Beta version) #\n'+
           '#########################################################################\n'+
           'The authors of specific programs should be referenced where applicable::\n\n'+
           'AMPLE: To be added\n'+
           'SHELX:  "A short history of SHELX". Sheldrick, G.M. (2008). Acta Cryst. A64, 112-122/n/n'+

           'SCWRL: G. G. Krivov, M. V. Shapovalov, and R. L. Dunbrack, Jr. Improved prediction of protein side-chain conformations with SCWRL4. Proteins (2009).\n\n'+


           'Theseus: THESEUS: Maximum likelihood superpositioning and analysis of macromolecular structures.\n'+
           'Theobald, Douglas L. & Wuttke, Deborah S. (2006b) Bioinformatics 22(17):2171-2172 [Open Access]\n'+
           'Supplementary Materials for Theobald and Wuttke 2006b.\n'+

           'MrBUMP: R.M.Keegan and M.D.Winn (2007) Acta Cryst. D63, 447-457\n'+


           'CCP4: Collaborative Computational Project, Number 4. (1994), The CCP4 Suite: Programs\n'+
           'for Protein Crystallography. Acta Cryst. D50, 760-763\n\n'+
           'MOLREP: A.A.Vagin & A.Teplyakov (1997) J. Appl. Cryst. 30, 1022-1025\n\n'+

           'PHASER: McCoy, A.J., Grosse-Kunstleve, R.W., Adams, P.D., Winn, M.D.,\n'+
           'Storoni, L.C. & Read, R.J. (2007)\n'+
           'Phaser crystallographic software J. Appl. Cryst. 40, 658-674\n\n'+

           'REFMAC: G.N. Murshudov, A.A.Vagin and E.J.Dodson, (1997) Refinement of Macromolecular\n'+
           'Structures by the Maximum-Likelihood Method. Acta Cryst. D53, 240-255\n\n'+

           'SPICKER: Y. Zhang, J. Skolnick, SPICKER: Approach to clustering protein structures for near-native model selection, Journal of Computational Chemistry, 2004 25: 865-871\n'+

           'MaxCluster: http://www.sbg.bio.ic.ac.uk/maxcluster/\n')
RUNNING.flush()




if DEBUG ==True:
  print PDB_code
os.chdir(RunDir)
  
outfasta=os.path.join(RunDir, PDB_code+'_.fasta')
fasta_parser.parse_fasta(FASTA, outfasta)
FASTA=outfasta
#####make frags 

if MakeFrags == True:
  print '----- making fragments--------\n'
  RUNNING.write('----- making fragments--------\n')
  RUNNING.flush()
  frags_dir = RunDir + '/frags'
  os.system('mkdir ' + frags_dir)
  cmd = Make_fragents_exe + ' -rundir ' + frags_dir + ' -id ' + PDB_code + ' '+FASTA+ ' -nojufo -nosam -noprof '+ nohoms +'>frag_log' 
  if DEBUG == False:
    print Make_fragents_exe + ' -rundir ' + frags_dir + ' -id ' + PDB_code + ' '+FASTA+ ' -nojufo -nosam -noprof  ' +nohoms 

  if DEBUG == True: 
      os.system(Make_fragents_exe + ' -rundir ' + frags_dir + ' -id ' + PDB_code + ' '+FASTA+ ' -nojufo -nosam -noprof '+ nohoms +'>frag_log'   ) 

  else:
      p = subprocess.call(cmd, shell = True, stdout=PIPE, stderr=PIPE )
  frags_3_mers = frags_dir + '/aa' +PDB_code+'03_05.200_v1_3'
  frags_9_mers = frags_dir + '/aa' +PDB_code+'09_05.200_v1_3'

  if not os.path.exists(frags_3_mers):
     print 'Error in making fragments'
     sys.exit()
  if not os.path.exists(frags_9_mers):
     print 'Error in making fragments'
     sys.exit()

  RUNNING.write('Fragments done\n3mers at: '+frags_3_mers+'\n9mers at: '+frags_9_mers+'\n\n')
  print' Fragments Done\n3mers at: '+frags_3_mers+'\n9mers at: '+frags_9_mers+'\n\n'



###modeling
insert_Rosetta_command=''
if INSERT_DOMAIN==True:
    fas=open(FASTA)
    seq=''
    for line in fas:
     if not re.search('>', line):
      seq+=line.rstrip('\n')
    length=0
    for x in seq:
     if re.search('\w', x):
      length+=1


    print 'restricting termini distance',  domain_termini_distance
    constraints_file = os.path.join(RunDir, 'constraints')
    conin=open(constraints_file,"w")
    conin.write('AtomPair CA 1 CA '+str(length)+' GAUSSIANFUNC '+str(domain_termini_distance)+' 5.0 TAG')
    insert_Rosetta_command=' -constraints:cst_fa_file '+ constraints_file + ' -constraints:cst_file '+ constraints_file + ' '
     


print  '----- making Rosetta models--------\n' 
print 'making '+str(NMODELS)+' models...'
RUNNING.write('----- making models--------\n')
RUNNING.flush()




if ImportTemplate ==True:
       CCline += ' -in:file:native ' + template + ' -abinitio:steal_3mers True -abinitio:steal_9mers True -abinitio:start_native True -templates:force_native_topology True'


if MakeModels == True:
  PATH_TO_MODELS = RunDir + '/models'
      
  # If we are running with cluster support submit all modelling jobs to the cluster queue
  if CLUSTER:
      seed_list=[]

      # Generate the list of random seeds
      while len(seed_list) < NMODELS:
        seed=random.randint(1000000, 4000000)
        if seed not in seed_list:
           seed_list.append(seed)

      # Invoke the cluster run class
      cluster_run=clusterize.ClusterRun()
      cluster_run.QTYPE="SGE"
      cluster_run.ALLATOM=ALLATOM
      cluster_run.setupModellingDir(RunDir)
      cluster_run.setScwrlEXE(SCWRL)
  
      # loop over the number of models and submit a job to the cluster
      for i in range(NMODELS):
        cluster_run.modelOnCluster(RunDir, 1, i+1, ROSETTA_PATH, ROSETTA_DB, FASTA, frags_3_mers, frags_9_mers, seed_list[i], insert_Rosetta_command+CCline)

      # Monitor the cluster queue to see when all jobs have finished
      cluster_run.monitorQueue()

  else:
      previous_seeds = [0]    #make random seeds  (1000000, 6000000) ! Must be unique seeds!!!!
      proc = 1
      while proc < NProc +1:
        new_seed = random.randint(1000000, 4000000)  
        seed_present = False

        for seed in previous_seeds:
           if new_seed == seed:
             seed_present = True
             break

        if seed_present == False:
          previous_seeds.append(new_seed)
          proc +=1
      if DEBUG == True:
         print previous_seeds

      split_jobs =  NMODELS / NProc   ### split jobs between processors
      remainder =   NMODELS % NProc
      jobs = [0]      
      proc = 1
      while proc < NProc +1:
        jobs.insert(proc, split_jobs)
        proc +=1
      jobs[-1] = jobs[-1] + remainder    
     # print jobs  ##################################


 

      os.system('mkdir '+ RunDir +'/models')
      PATH_TO_MODELS = RunDir +'/models'

      proc = 1
      while proc < NProc +1:
       if DEBUG == True:
          print proc
 
       os.system('mkdir '+ RunDir + '/models_'+str(proc))
       os.chdir(RunDir + '/models_'+str(proc))

       

       if ALLATOM == False:
          RUNNING.write(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom false   -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')
          RUNNING.flush()

          os.system(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom false   -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')

       else:
          RUNNING.write(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom true -abinitio:relax  -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')
          RUNNING.flush()

          os.system(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom true -abinitio:relax   -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')


       proc +=1




### wait for all models to be made, check number for each job

      no_models_to_make = NMODELS
      no_models_have = 0 
      finished_models = 0 
      while no_models_have !=  no_models_to_make:
        no_models_have = 0
        proc = 1
        while proc < NProc +1:
          list_of_files = [file for file in os.listdir(RunDir +'/models_'+str(proc) ) if file.lower().endswith('.pdb')]


          no_models_have  += len(list_of_files)
          proc+=1
        if no_models_have > finished_models:
           if DEBUG == True:
              print 'Number of models made so far = ' + str(no_models_have)
           else:
              divisor = no_models_to_make/10
              if divisor !=0:
                if no_models_have !=0:
                  if no_models_have%divisor == 0:  
                     print 'Number of models made so far = ' + str(no_models_have)

           finished_models = no_models_have
        if no_models_have ==  no_models_to_make:
           break
        time.sleep(5)       
   
 
     
   

      
   
      LOG = open(RunDir+'/LOG', "a")
      print 'MODELLING DONE'
## got them all   Must Delete Models or job will hang -----------



      MODELLING_time_stop=time.time()
      cat_string = ''

     # RunDir +'/models'
      proc = 1
      while proc < NProc +1:
         if DEBUG == True:
            print 'nproc', proc
         
         add_sidechains_SCWRL(SCWRL,   RunDir + '/models_'+str(proc),   RunDir + '/models',  str(proc), DEBUG )
         cat_string += RunDir + '/OUT_' + str(proc) +'  '
         #os.system('rm -r '+RunDir + '/models_'+str(proc) )
         proc+=1
    
      os.chdir(RunDir)
     # print 'Your models are in: ' +cat_string


     ####### keep or delete run files
if MakeModels == False:
  PATH_TO_MODELS = MODELS_LOCATION
  previous_seeds = []
  seed_list = []
RUNNING.write('\nModelling complete - models stored in:\n   '+PATH_TO_MODELS+'\n\n')
sys.stdout.write('\n\nModelling complete - models stored in:\n   '+PATH_TO_MODELS+'\n\n')

###############get seedlist

if CLUSTER:
   for seed in seed_list:
     seedlog.write(str(seed) + '\n')

   seedlog.close()
else:
   for seed in  previous_seeds:
      seedlog.write(str(seed) + '\n')
   seedlog.close()


#--------------------------------------------
#check if models are present regardless
#--------------------------------------------


#--------------------------------------
# Do the clustering  
#---------------------------------------
USE_SPICKER = True
if ENSEMBLE_import ==False:

 if USE_SPICKER==False:
    noClusters=1

    levels = [20,25,30,40,50,60]   # clustering levels
    if NMODELS > 1000:
     levels = [20,25,30,40,50,60,70,80,90,95] 

    sys.stdout.write('----------CLUSTERING---------\n')
    RUNNING.write('----------CLUSTERING---------\n')
    RUNNING.write('Default clustering to find only the largest cluster (see developemnt version for alternate clustering methods)')
    RUNNING.flush()
    cluster_path = RunDir + '/clusters/'  # outpath for clusters
    os.system('mkdir '+ RunDir + '/clusters')


    cluster_results = cluster_entropy.RUN_CLUSTER(levels, PATH_TO_MODELS, LGA, cluster_path,  NProc, NMODELS)


    sys.stdout.write('Clustering Done!\n')
    RUNNING.write('Clustering Done! your results:\n')
    i = 0
    while i < len(cluster_results):
     RUNNING.write('at level ' +str(levels[i]) + ' cluster size is ' + str(cluster_results[i])+'\n' )
     i+=1
    RUNNING.flush()


#----------------------------------------
#pick a clustering level
#----------------------------------------
#  default method of picking a cluster  cutoffs <50 >5:


    trunc_level = 'nan'
    print levels, cluster_results
    i = 0
    while i < len(cluster_results):
     if  cluster_results[i] <50 and cluster_results[i] >2:
      trunc_level = levels[i]
      break
     i+=1
    print trunc_level


#if none exist in range, go higher:
    if trunc_level == 'nan':
      i = 0
      while i < len(cluster_results):
        if  cluster_results[i] >2 :
          trunc_level = levels[i]
        i+=1

    print trunc_level

#-------------------------------------
#Truncate
#-------------------------------------
    RUNNING.write('\n----------Truncating---------\n')
    RUNNING.flush()
    os.system('mkdir '+RunDir+'/fine')
    os.chdir( RunDir+'/fine')
    models_path = RunDir + '/clusters/cluster_'+str(trunc_level)+'/sorted_cluster_0'

    print THESEUS, models_path, RunDir+'/fine', ROSETTA_cluster 

    Strict= False #  Default = True
    if Strict== True:
     list_of_ensembles = truncateedit.truncate(THESEUS, models_path, RunDir+'/fine', ROSETTA_cluster, ROSETTA_DB )
    if Strict== False:
      
      list_of_ensembles = truncateedit_MAX.truncate(THESEUS, models_path, RunDir+'/fine', MAX, percent, FIXED_INTERVALS )

    RUNNING.write('Truncating done!\n')
    RUNNING.flush()

#-------------------------------------
#fix sidechains
#------------------------------------
    os.system('mkdir '+RunDir+'/ensembles')
    for each_ens in list_of_ensembles:
     SCWRL_edit.edit_sidechains(each_ens, RunDir+'/ensembles/')

    final_ensembles =[]
    for infile in glob.glob( os.path.join(RunDir+'/ensembles', '*.pdb') ):
      final_ensembles.append(infile)

#-------------------------------------
# Spicker Alternative for clustering then MAX 
#------------------------------------
 if USE_SPICKER==True:

    ResultsPath = RunDir+'/RESULTS'
    if not os.path.exists(RunDir+'/RESULTS'):
       os.mkdir(RunDir+'/RESULTS')


  



    #noClusters=1

    print '----- Clustering models --------\n'
    run_spicker.RUN_SPICKER(PATH_TO_MODELS, RunDir+'/spicker_run', SPICKEREXE, int(noClusters) , RunDir )
    samples = 1
    print '\nClusteing Done. using the first '+str(samples)+' clusters\n'
    while samples < int(noClusters)+1:
      models_path = RunDir + '/S_clusters/cluster_'+str(samples)
      print '----- Truncating models for cluster '+str(samples)+' --------\n'
      if not os.path.exists(RunDir+'/fine_cluster_'+str(samples)):
         os.mkdir(RunDir+'/fine_cluster_'+str(samples))

      os.chdir(RunDir+'/fine_cluster_'+str(samples) )    
      if Ensembler == False:
              list_of_ensembles = truncateedit_MAX.truncate(THESEUS, models_path, RunDir+'/fine_cluster_'+str(samples), MAX, percent, FIXED_INTERVALS  )

      if Ensembler == True:
              list_of_ensembles = truncateedit_MAX.truncate_Phenix(PHENIX, models_path, RunDir+'/fine_cluster_'+str(samples), MAX, percent, FIXED_INTERVALS  )

     



 
      
      os.system('mkdir '+RunDir+'/ensembles_'+str(samples))
      for each_ens in list_of_ensembles:
        SCWRL_edit.edit_sidechains(each_ens, RunDir+'/ensembles_'+str(samples)+'/')

      final_ensembles =[]
      for infile in glob.glob( os.path.join(RunDir+'/ensembles_'+str(samples), '*.pdb') ):
         final_ensembles.append(infile)



      bump_dir = os.path.join(RunDir, 'MRBUMP')
      if not os.path.exists(bump_dir):
       os.mkdir(bump_dir)
      os.chdir(bump_dir)
      if MISSING_DOMAINS == False:
         if CLUSTER:
            sys.stdout.write("Running MR and model building on a cluster\n\n")
   
            mrBuild=clusterize.ClusterRun()
            mrBuild.QTYPE="SGE"
   
            mrBuildClusterDir=os.path.join(bump_dir, "cluster_run"+str(samples))
            os.mkdir(mrBuildClusterDir)
   
            mrBuild.HKLIN = MTZ
            mrBuild.LABIN["F"]         = flag_F
            mrBuild.LABIN["SIGF"]      = flag_SIGF
            mrBuild.LABIN["FreeR_flag"] = flag_FREE
            mrBuild.SEQIN = FASTA
            mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)
   
            # Reset the queue list
            mrBuild.qList=[]
            jobID=0
            for pdbfile in final_ensembles:
               mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID)
               jobID=jobID+1
            mrBuild.monitorQueue()

            shutil.rmtree(RunDir+'/fine_cluster_'+str(samples))
            shutil.rmtree(RunDir+'/pre_models')
            for l in os.listdir(RunDir+'/spicker_run'):
              if os.path.splitext(l)[1] == 'pdb':
                   os.remove(RunDir+'/spicker_run/'+l)
            os.remove(RunDir+'/spicker_run/rep1.tra1')



            #cleanup
           # for each_run in os.listdir(mrBuildClusterDir ):
            #   if os.path.isdir(  os.path.join(mrBuildClusterDir, each_run)):
            #      name=re.split('_', each_run)
            #      mrBuildOutputDir=os.path.join(bump_dir, "cluster_run"+str(samples)+"result"+name[1]) 
            #      os.mkdir(mrBuildOutputDir)                   
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","phaser_shelx" ),mrBuildOutputDir  )
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","molrep_shelx" ),mrBuildOutputDir  )  
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","data" ),mrBuildOutputDir  )               
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "logs" ),mrBuildOutputDir  )               
            #shutil.rmtree(mrBuildClusterDir)
   
      # Monitor the cluster queue to see when all jobs have finished

          
         if not CLUSTER:
            sys.stdout.write('Truncating Done for cluster '+str(samples)+"\n\n")
            sys.stdout.write('----- Running MRBUMP (cluster '+str(samples)+')--------\n\n')
            sys.stdout.write('Created '+str(len(final_ensembles))+' ensembles,   running '+str(len(final_ensembles))+' jobs for cluster '+str(samples)+'\n') 

            bump_dir = os.path.join(RunDir, 'MRBUMP_cluster'+str(samples))
            print bump_dir
            
            os.mkdir(bump_dir) 
            os.chdir(bump_dir)
            split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
            run_mr_bump_shelx_parallel.split_into_runs(MTZ, split_ensembles, bump_dir, FASTA, NProc, flag_SIGF, flag_F, flag_FREE, noASU, EarlyTerminate, ResultsPath, NoShelx, NoShelxCycles)
            if NoShelx == False: 
              Final_display_results.make_log(bump_dir, os.path.join(RunDir, 'Final_results.log'))
            if NoShelx ==  True:
              resultslog = open(ResultsPath+'/Results.log', "w")
              print 'getting results from:'
              print bump_dir
              for mrbumplog in os.listdir(bump_dir):
                  if re.search('.log', mrbumplog):
                      #print mrbumplog
                      for line in open(mrbumplog):
                        if re.search('^(\d)\s*loc0_', line):
                         if not re.search('method', line):
                           print line
                           resultslog.write(line)
              resultslog.close()
              sys.exit()

      if MISSING_DOMAINS == True:
        if  CLUSTER:
            print 'this needs to be added'
# --------------- missing domains cluster

      if MISSING_DOMAINS == True:
        if  CLUSTER:
            sys.stdout.write("Running MR and model building on a cluster\n\n")
   
            mrBuild=clusterize.ClusterRun()
            mrBuild.QTYPE="SGE"
   
            mrBuildClusterDir=os.path.join(bump_dir, "cluster_run"+str(samples))
            os.mkdir(mrBuildClusterDir)
   

            mrBuild.HKLIN = MTZ
            mrBuild.LABIN["F"]         = flag_F
            mrBuild.LABIN["SIGF"]      = flag_SIGF
            mrBuild.LABIN["FreeR_flag"] = flag_FREE
            mrBuild.SEQIN = domain_all_chain_fasta
            mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)

#            mrBuild.FIXEDIN='FIXED_XYZIN '+domain_all_chains_pdb+' IDENTIY 0.6 \n'

            # Reset the queue list
            mrBuild.qList=[]
            jobID=0
            for pdbfile in final_ensembles:
               mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID ,  domain_all_chains_pdb , '0.6')
               jobID=jobID+1
            mrBuild.monitorQueue()

            shutil.rmtree(RunDir+'/fine_cluster_'+str(samples))
            shutil.rmtree(RunDir+'/pre_models')
            for l in os.listdir(RunDir+'/spicker_run'):
              if os.path.splitext(l)[1] == 'pdb':
                   os.remove(RunDir+'/spicker_run/'+l)
            os.remove(RunDir+'/spicker_run/rep1.tra1')




            #cleanup
            #for each_run in os.listdir(mrBuildClusterDir ):
            #   if os.path.isdir(  os.path.join(mrBuildClusterDir, each_run)):
            #      name=re.split('_', each_run)
            #      mrBuildOutputDir=os.path.join(bump_dir, "cluster_run"+str(samples)+"result"+name[1]) 
            #      os.mkdir(mrBuildOutputDir)                   
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","phaser_shelx" ),mrBuildOutputDir  )
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","molrep_shelx" ),mrBuildOutputDir  )  
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","data" ),mrBuildOutputDir  )               
            #      shutil.move (os.path.join(mrBuildClusterDir, each_run, "logs" ),mrBuildOutputDir  )               
            #shutil.rmtree(mrBuildClusterDir)
   
#-------------------------------------
        else:
         print domain_all_chains_pdb
         print domain_all_chain_fasta
         bump_dir = os.path.join(RunDir, 'MRBUMP_cluster'+str(samples))
         os.mkdir(bump_dir) 
         os.chdir(bump_dir)
         split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
         run_mr_bump_shelx_parallel.split_into_runs_domains(MTZ, split_ensembles, bump_dir, domain_all_chain_fasta , NProc, domain_all_chains_pdb)
         Final_display_results.make_log(bump_dir, os.path.join(RunDir, 'Final_results.log'))


      samples+=1


    time_stop=time.time()
    elapsed_time= time_stop - time_start
    run_in_min=elapsed_time/60
    run_in_hours = run_in_min/60
    print '\nMR and shelx DONE \n ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n'
    RUNNING.write('\nMR and shelx ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n')
    RUNNING.flush()
    RUNNING.write('The authors of specific programs should be referenced where applicable::\n\n'+
           'AMPLE: To be added\n'+
           'SHELX: "A short history of SHELX". Sheldrick, G.M. (2008). Acta Cryst. A64, 112-122/n/n'+

           'SCWRL: G. G. Krivov, M. V. Shapovalov, and R. L. Dunbrack, Jr. Improved prediction of protein side-chain conformations with SCWRL4. Proteins (2009).\n\n'+


           'Thsesus: THESEUS: Maximum likelihood superpositioning and analysis of macromolecular structures.\n'+
           'Theobald, Douglas L. & Wuttke, Deborah S. (2006b) Bioinformatics 22(17):2171-2172 [Open Access]\n'+
           'Supplementary Materials for Theobald and Wuttke 2006b.\n'+


           'MrBUMP: R.M.Keegan and M.D.Winn (2007) Acta Cryst. D63, 447-457\n'+


           'CCP4: Collaborative Computational Project, Number 4. (1994), The CCP4 Suite: Programs\n'+
           'for Protein Crystallography. Acta Cryst. D50, 760-763\n\n'+

           'MOLREP: A.A.Vagin & A.Teplyakov (1997) J. Appl. Cryst. 30, 1022-1025\n\n'+

           'PHASER: McCoy, A.J., Grosse-Kunstleve, R.W., Adams, P.D., Winn, M.D.,\n'+
           'Storoni, L.C. & Read, R.J. (2007)\n'+
           'Phaser crystallographic software J. Appl. Cryst. 40, 658-674\n\n'+

           'REFMAC: G.N. Murshudov, A.A.Vagin and E.J.Dodson, (1997) Refinement of Macromolecular\n'+
           'Structures by the Maximum-Likelihood Method. Acta Cryst. D53, 240-255\n\n'+

           'SPICKER: Y. Zhang, J. Skolnick, SPICKER: Approach to clustering protein structures for near-native model selection, Journal of Computational Chemistry, 2004 25: 865-871\n'+

           'MaxCluster: http://www.sbg.bio.ic.ac.uk/maxcluster/\n')
    RUNNING.flush()
    RUNNING.close()

   # os.system('tar -cvf '+PDB_code+'_' + RunDir+'.tar '+RunDir)
   # os.system('gzip ' +PDB_code+'_'+ RunDir+'.tar')
   # os.system('mv '+ PDB_code+'_'+  RunDir+'.tar.gz /data2/jac45 ')
   # os.system('rm '+RunDir)
    #stop here
    sys.exit()  # the above is the only code that should be used



#------------------------------------
# END
#----------------------------------
time_stop=time.time()

elapsed_time= time_stop - time_start
run_in_min=elapsed_time/60
run_in_hours = run_in_min/60

RUNNING.write('\nMODELLING and ASSEMBLY ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n')
RUNNING.flush()

if ENSEMBLE_import ==True:
 final_ensembles =[]
 for infile in glob.glob( os.path.join(ENSEMBLES, '*.pdb') ):
   final_ensembles.append(infile)

ResultsPath = RunDir+'/RESULTS'
if not os.path.exists(RunDir+'/RESULTS'):
       os.mkdir(RunDir+'/RESULTS')



#--------------Import into MrBUMP here-------------------
RUNNING.write('Running MrBUMP\nMR LOGS in '+RunDir+'/MRBUMP')
RUNNING.flush()

#os.system('mkdir ' + RunDir+'/MRBUMP')
bump_dir = os.path.join(RunDir, 'MRBUMP')
os.mkdir(bump_dir)
os.chdir(bump_dir)
ResultsPath = RunDir+'/RESULTS'
if MISSING_DOMAINS == False:
   if CLUSTER:
      sys.stdout.write("Running MR and model building on a cluster\n\n")
   
      mrBuild=clusterize.ClusterRun()
      mrBuild.QTYPE="SGE"
   
      mrBuildClusterDir=os.path.join(bump_dir, "cluster_run")
      os.mkdir(mrBuildClusterDir)
   
      mrBuild.HKLIN = MTZ
      mrBuild.LABIN["F"]         = flag_F
      mrBuild.LABIN["SIGF"]      = flag_SIGF
      mrBuild.LABIN["FreeR_flag"] = flag_FREE
      mrBuild.SEQIN = FASTA
      mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)
   
      # Reset the queue list
      mrBuild.qList=[]
      jobID=0
      for pdbfile in final_ensembles:
         mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID)
         jobID=jobID+1




      # Monitor the cluster queue to see when all jobs have finished
      mrBuild.monitorQueue()
   else: 
      split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
      run_mr_bump_shelx_parallel.split_into_runs(MTZ, split_ensembles, bump_dir, FASTA, NProc, flag_SIGF, flag_F, flag_FREE, noASU, EarlyTerminate, ResultsPath, NoShelx, NoShelxCycles)
      Final_display_results.make_log(bump_dir, os.path.join(RunDir, 'Final_results.log'))

      if NoShelx == False:
               Final_display_results.make_log(bump_dir, os.path.join(RunDir, 'Final_results.log'))
      if NoShelx ==  True:
              resultslog = open(ResultsPath+'/Results.log', "w")
              print 'getting results from:'
              print bump_dir
              for mrbumplog in os.listdir(bump_dir):
                  if re.search('.log', mrbumplog):
                      #print mrbumplog
                      for line in open(mrbumplog):
                        if re.search('^(\d)\s*loc0_', line):
                         if not re.search('method', line):
                           print line
                           resultslog.write(line)
              resultslog.close()
              sys.exit()




if MISSING_DOMAINS == True:
  if  CLUSTER:

      sys.stdout.write("Running MR and model building on a cluster\n\n")
   
      mrBuild=clusterize.ClusterRun()
      mrBuild.QTYPE="SGE"
   
      mrBuildClusterDir=os.path.join(bump_dir, "cluster_run")
      os.mkdir(mrBuildClusterDir)
   
      mrBuild.HKLIN = MTZ
      mrBuild.LABIN["F"]         = flag_F
      mrBuild.LABIN["SIGF"]      = flag_SIGF
      mrBuild.LABIN["FreeR_flag"] = flag_FREE
      mrBuild.SEQIN = domain_all_chain_fasta
      mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)
   
      # Reset the queue list
      mrBuild.qList=[]
      jobID=0
      for pdbfile in final_ensembles:
         mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID, domain_all_chains_pdb, 0.6)
         jobID=jobID+1



  else:
   print domain_all_chains_pdb
   print domain_all_chain_fasta
   print 'the input is fixed ', FIXED_INPUT


   split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
   run_mr_bump_shelx_parallel.split_into_runs_domains(MTZ, split_ensembles, bump_dir, domain_all_chain_fasta , NProc, domain_all_chains_pdb, FIXED_INPUT)
   Final_display_results.make_log(bump_dir, os.path.join(RunDir, 'Final_results.log'))




time_stop=time.time()
elapsed_time= time_stop - time_start
run_in_min=elapsed_time/60
run_in_hours = run_in_min/60

RUNNING.write('\nMR and shelx ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n')
RUNNING.flush()

